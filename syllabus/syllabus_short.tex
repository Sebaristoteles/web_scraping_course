\documentclass[a4paper]{article}
\usepackage{hyperref}
\usepackage{graphicx}

\begin{document}

%%% Manual title page with logo
% BCCP log
\includegraphics[width=80px]{../misc/bccp_logo_transparent.png}
\vspace{1cm}

\begin{center}
\textbf{\Large BCCP Web Scraping Course} \vspace{0.3cm}

Julian Harke and Kevin Tran\footnote{Julian is a Research Fellow at the WZB and a PhD student at Vrije Universiteit Amsterdam. Kevin is a PhD student at the DIW Graduate Center and Technische Universit\"at Berlin. Both are members of the Berlin Centre for Consumer Policies (BCCP).} \vspace{0.3cm}

June 24, 2019, 09:30 - 12:30 \\
June 25, 2019, 09:30 - 12:30 \\
June 26, 2019, 14:00 - 17:00
\end{center}

\paragraph{Description} This short course is meant to give an overview over the most common web scraping techniques. The idea is to have an interactive course in which the participants get their hands on actual code and work with it. Therefore, please bring your own computers, if possible. The main aim is to cover several approaches that are needed to scrape different types of data from different websites. In the end, participants should have an idea of how to approach the task of web scraping any website they are interested in.
As an exercise spanning the entirety of the course, we propose that participants can choose a website that they are interested in and try to build a scraper using the codes and knowledge they gain during the course.

The codes for the course are written in Python. The course also includes a very short introduction to Python but due to the limited time, we will not be able to cover all the Python concepts needed. Therefore, it would be helpful if you look at some preparatory material to get familiar with the language a bit. In particular, please also take the time to install a Python distribution on your computer and some of the packages that we will need for the course.

The course is split up in three half days. On day 1, we will cover a short introduction to Python and some basic web scraping concepts. Then, we will look at how to gather data if an Application Programming Interface (API) is available. On day 2, we will cover techniques for retrieving information from HTML code such as HTML parsing and text pattern matching. On day 3, we will look into browser automation, a technique that is necessary in particular to scrape websites that load dynamically. Finally, we will leave some time to discuss issues with your own scraper. \\

\noindent\textbf{To participate, please register with Juliane Metzner (\href{mailto:jmetzner@diw.de}{jmetzner@diw.de}).}

%\section{Prerequisites}

%We will give you a "very short introduction to python". Nevertheless,
%it will be easier to follow if you know some basic concepts of Python.\\

%Basic concepts that are useful:
%\begin{itemize}
%    \item How to load packages in python.
%    \item How to write a function in python.
%\end{itemize}

%These basic concepts are covered here:
%LINK

%\section{Further reading}

%\begin{itemize}
%    \item{
%      \href{
%        http://drivendata.github.io/cookiecutter-data-science/}{
%        \textbf{Cookiecutter Data Science Project Template}}}
%\end{itemize}

%\newpage
%\section{Schedule}

%\begin{itemize}
%	\item June 24: 09:30 - 12:30
%		\begin{itemize}
%			\item Very short introduction to Python
%			\item Basics of web scraping
%			\item APIs
%		\end{itemize}
%	\item June 25: 09:30 - 12:30
%		\begin{itemize}
%			\item HTML parsing
%			\item Text pattern matching
%		\end{itemize}
%	\item June 26: 14:00 - 17:00
%		\begin{itemize}
%			\item Browser automation (Selenium)
%			\item Questions, Troubleshooting of own code
%		\end{itemize}
%\end{itemize}

\end{document}
