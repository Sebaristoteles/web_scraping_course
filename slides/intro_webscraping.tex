\begin{frame}{Introduction to web scraping}
\begin{itemize}
	\item Basic idea: Turn information on website to structured data
	% Screenshot of webpage and corresponding data
	\item Typical workflow:
	\begin{enumerate}
		\item Look at website to decide best approach
		\begin{itemize}
			\item Is an Application Programming Interface (API) available?
			\item Do the HTML elements have fixed names?
			\item Does the page load statically or dynamically?
		\end{itemize}
		\item Load the page and save the source code/API result
		\item Convert source code/API result to Python object
		\item Take wanted information from Python object, convert to DataFrame, and save
	\end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}{Some concepts}
\begin{itemize}
	\item APIs
	\item HTML parsing vs text matching
	\item Static vs dynamic websites
\end{itemize}
\end{frame}

\begin{frame}{APIs}
\begin{itemize}
	\item If available, a convenient way to get pre-structured data (usually JSON or XML).
	\item Example: OpenStreetMap (OSM) (\url{https://www.openstreetmap.org})
	\begin{itemize}
		\item When searching manually, results can be shown as XML. Automating the search on OpenStreetMap and clicking on the relevant links would therefore be a way to save this data.
		\item However, OSM offers several APIs that simplify this task. One API is the Nominatim API (\url{https://nominatim.openstreetmap.org}).
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{API example: Nominatim API for OSM}
\begin{itemize}
	\item See \url{https://nominatim.org/release-docs/develop/api/Search/} for documentation on search syntax
	\item Search for 'diw berlin' and return as JSON: \url{https://nominatim.openstreetmap.org/search?q=diw+berlin&format=json}
\end{itemize}

\end{frame}

\begin{frame}{HTML parsing}
% Example of website screenshot and HTML code
\begin{itemize}
	\item Use structure of HTML code to find needed information.
	\item Works best if the source code has a fixed structure and element names are constant or follow some pattern.
	\item Two basic concepts: Navigation and searching
	\begin{itemize}
		\item Navigation: Start at one point of the HTML document and navigate along the structure of the document (e.g. go to children tags or sibling tags)
		\item Searching: Search for specific HTML elements using their tag name (e.g. \mintinline{html}{<div>} or \mintinline{html}{<span>}) and values of attributes like \mintinline{html}{class} or \mintinline{html}{id}
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{HTML parsing example: eBay search results}
\begin{itemize}
	\item Look at results for 'star wars blu ray' on eBay: \url{https://www.ebay.de/sch/i.html?_nkw=star+wars+blu+ray}
	\item Most browsers have a feature to look at source code (e.g. in Chrome, you can right click on any website element and click on 'Inspect').
	\item On eBay, the HTML tags containing certain content always have the same name, this simplifies HTML parsing.
	\item For example, the tag \mintinline{html}{<div id="ResultSetItems">} contains all results. Inside this tag, the individual listings are saved in tags called \mintinline{html}{<li class="sresult">}. In Chrome, you can also look for elements using the XPATH syntax (e.g. for the individual listings: \textit{//li[contains(@class,'sresult')]}). More information on XPATH here: \url{https://www.w3schools.com/xml/xpath_syntax.asp}
\end{itemize}
\end{frame}

\begin{frame}{Text pattern matching}
% Example of website screenshot and HTML code with random names
\begin{itemize}
	\item If the HTML code is not well-structured or names change, text pattern matching is an alternative.
	\item Idea: Look at HTML elements in which wanted information is stored, identify patterns, and match using a regular expression
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Example of website without clear HTML tag names: Airbnb}
\begin{itemize}
	\item Search for homes in Berlin-Mitte: \url{https://www.airbnb.de/s/Berlin-Mitte--Berlin/homes?query=Berlin-Mitte\%2C\%20Berlin}
	\item Say you wanted to get the number of results for this search. The element does not have a clear name. Using HTML parsing is still possible but is prone to errors. Instead, one could match on a regular expression, e.g.
\begin{minted}{html}
re.findall('[0-9]{1,2} - [0-9]{1,2} von ([0-9 +]+) Unterk√ºnfte', srccode)
\end{minted}
\end{itemize}
\end{frame}

\begin{frame}{Static vs dynamic websites}
% Example of website screenshot and HTML code with random names
\begin{itemize}
	\item On static websites, the entire content is loaded immediately. E.g. eBay: \url{https://www.ebay.de/sch/i.html?_nkw=star+wars+blu+ray}
	\item On dynamic websites, content may not load instantaneously or only after user action, usually making them more complicated to scrape. E.g. Airbnb: \url{https://www.airbnb.de/s/Berlin-Mitte--Berlin/homes?query=Berlin-Mitte\%2C\%20Berlin} (Try disabling JavaScript in your browser and reloading the page).
	% Show examples of static and dynamic websites and what happens if loading with requests
	\item Getting the complete source code from a dynamic website can be done with browser automation. The idea is to open a website in an actual browser (and interacting with it if necessary) and save the source code of the content from there.
\end{itemize}
\end{frame}

\begin{frame}[fragile,allowframebreaks]{Important Python packages}
\begin{itemize}
	\item \mintinline{python}{requests}: To load URL and recover source code (for static web pages), e.g.:
\begin{minted}{python}
import requests # Import package
url = "http://www.bccp-berlin.de/events/all-events" # Define URL to load
r = requests.get(url) # Load URL
srccode = r.text # Save source code
\end{minted}

\framebreak

	\item \mintinline{python}{selenium}: For browser automation
\begin{minted}{python}
from selenium import webdriver # Import webdriver class from selenium module
from selenium.webdriver.chrome.options import Options # Load Options class
    # from chrome.options to set options for the Chrome webdriver
chrome_options = Options() # Create instance of Chrome options
chrome_options.binary_location = browser_app # Set the location where the
    # browser is located
driver = webdriver.Chrome(browser_driver, options = chrome_options) # Start
    # the browser driver (browser_driver contains the location to the
    # webdriver
url = "https://www.berlin-econ.de/events" # Define URL to load
driver.get(url) # Load URL
html = driver.page_source # Save source code
\end{minted}

\framebreak

	\item \mintinline{python}{beautifulsoup4}: To turn HTML code to navigable Python object
\begin{minted}{python}
from bs4 import BeautifulSoup # Load BeautifulSoup class from bs4 module
soup = BeautifulSoup(srccode, "lxml") # Convert source code to soup using
    # the "lxml" parser
\end{minted}

	\item \mintinline{python}{pandas}: To create DataFrames
\begin{minted}{python}
import pandas as pd # Load pandas module with short-cut pd
df = pd.DataFrame(resdict).T # Convert dictionary to DataFrame and transpose
df.to_csv(file_save) # Save df as csv (file_save contains the path to the file)
\end{minted}
\end{itemize}

\end{frame}