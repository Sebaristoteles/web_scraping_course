\begin{frame}{Introduction to Webscraping}
\begin{itemize}
	\item Basic idea: Turn information on website to structured data
	% Screenshot of webpage and corresponding data
	\item Typical workflow:
	\begin{enumerate}
		\item Look at website to decide best approach
		\begin{itemize}
			\item Is an Application Programming Interface (API) available?
			\item Do the elements have fixed names?
			\item Does the page load statically or dynamically?
		\end{itemize}
		\item Download information from URL
		\item Turn information into structured data and save
	\end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}{Some concepts}
\begin{itemize}
	\item 
	\item HTML parsing vs text matching
	\item Static vs dynamic websites
\end{itemize}
\end{frame}

\begin{frame}{APIs}
% Example of website screenshot and JSON result
\begin{itemize}
	\item If available, a convenient way to get pre-structured data (usually JSON or XML).
	\item Example: See 0_intro_webscraping.ipynb
\end{itemize}
\end{frame}

\begin{frame}{APIs}
% Example of website screenshot and JSON result
\begin{itemize}
	\item If available, a convenient way to get pre-structured data (usually JSON or XML).
	\item Example: See 0_intro_webscraping.ipynb
\end{itemize}
\end{frame}

\begin{frame}{Important Python packages}
\begin{itemize}
	\item {\tt requests}: To load URL and recover source code (for static web pages)
	\item {\tt beautifulsoup4}: To turn HTML code to navigable Python object
	\item {\tt selenium}: To automate browsers
	\item {\tt pandas}: To create DataFrames
\end{itemize}

\end{frame}